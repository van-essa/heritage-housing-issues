{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Feature Engineering Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Engineer features for Classification, Regression and Cluster models\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/cleaned/TrainSet.csv\n",
        "* inputs/datasets/cleaned/TestSet.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate a list with variables to engineer\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* #### Feature Engineering Transformers\n",
        "  * Ordinal Encoder: ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
        "\n",
        "  * Numerical Transformation: ['1stFlrSF', '2ndFlrSF', 'BsmtFinSF1', 'BsmtUnfSF', 'EnclosedPorch', \n",
        "  'GarageArea', 'GrLivArea', 'LotArea', 'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF', \n",
        "  'WoodDeckSF', 'TotalArea']\n",
        "\n",
        "    * Log Transformer: ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']\n",
        "\n",
        "    * Power Transformer: ['2ndFlrSF', 'BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'MasVnrArea', 'OpenPorchSF','TotalBsmtSF', 'WoodDeckSF']\n",
        "\n",
        "  * Outlier Trimmer: ['SalePrice', 'GrLivArea', 'TotalArea']\n",
        "\n",
        "    * Winsorizer: ['SalePrice', 'GrLivArea']\n",
        "  \n",
        "  * Smart Correlated Selection - Features to drop: ['1stFlrSF', 'GarageYrBlt']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Load Cleaned Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
        "TrainSet = pd.read_csv(train_set_path)\n",
        "TrainSet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_path = 'outputs/datasets/cleaned/TestSetCleaned.csv'\n",
        "TestSet = pd.read_csv(test_set_path)\n",
        "TestSet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now explore and evaluate which potential transformation we could do in our variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.6, PPS_Threshold =0.15,\n",
        "                  figsize=(12,10), font_annot=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Functions\n",
        "\n",
        "We will use the following custom function from [Code Institute](https://codeinstitute.net/se/). This function will help quick feature engineering on numerical and categorical variables to decide which transformation can better transform the distribution shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set(style=\"whitegrid\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df,analysis_type=None):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  - used for quick feature engineering on numerical and categorical variables\n",
        "  to decide which transformation can better transform the distribution shape \n",
        "  - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
        "\n",
        "  \"\"\"\n",
        "  check_missing_values(df)\n",
        "  allowed_types= ['numerical', 'ordinal_encoder',  'outlier_winsorizer']\n",
        "  check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "  list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "  \n",
        "  \n",
        "  # Loop in each variable and engineer the data according to the analysis type\n",
        "  df_feat_eng = pd.DataFrame([])\n",
        "  for column in df.columns:\n",
        "    # create additional columns (column_method) to apply the methods\n",
        "    df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "    for method in list_column_transformers:\n",
        "      df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "      \n",
        "    # Apply transformers in respectives column_transformers\n",
        "    df_feat_eng,list_applied_transformers = apply_transformers(analysis_type, df_feat_eng, column)\n",
        "\n",
        "    # For each variable, assess how the transformations perform\n",
        "    transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "  return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "  ### Check analyis type\n",
        "  if analysis_type == None:\n",
        "    raise SystemExit(f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "  if analysis_type not in allowed_types:\n",
        "      raise SystemExit(f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "def check_missing_values(df):\n",
        "  if df.isna().sum().sum() != 0:\n",
        "    raise SystemExit(\n",
        "        f\"There is missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "  ### Set suffix colummns acording to analysis_type\n",
        "  if analysis_type=='numerical':\n",
        "    list_column_transformers = [\"log_e\",\"log_10\",\"reciprocal\", \"power\",\"box_cox\",\"yeo_johnson\"]\n",
        "  \n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    list_column_transformers = ['iqr']\n",
        "\n",
        "  return list_column_transformers\n",
        "\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "\n",
        "\n",
        "  for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "    df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "\n",
        "  if analysis_type=='numerical':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_Numerical(df_feat_eng,column)\n",
        "  \n",
        "  elif analysis_type=='outlier_winsorizer':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_OutlierWinsorizer(df_feat_eng,column)\n",
        "\n",
        "  elif analysis_type=='ordinal_encoder':\n",
        "    df_feat_eng,list_applied_transformers = FeatEngineering_CategoricalEncoder(df_feat_eng,column)\n",
        "\n",
        "  return df_feat_eng,list_applied_transformers\n",
        "\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "  # For each variable, assess how the transformations perform\n",
        "  print(f\"* Variable Analyzed: {column}\")\n",
        "  print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "  for col in [column] + list_applied_transformers:\n",
        "    \n",
        "    if analysis_type!='ordinal_encoder':\n",
        "      DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "    \n",
        "    else:\n",
        "      if col == column: \n",
        "        DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "      else:\n",
        "        DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "  plt.figure(figsize=(4, 3))\n",
        "  sns.countplot(data=df_feat_eng, x=col,palette=['#432371'],order = df_feat_eng[col].value_counts().index)\n",
        "  plt.xticks(rotation=90) \n",
        "  plt.suptitle(f\"{col}\", fontsize=30,y=1.05)        \n",
        "  plt.show()\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "  sns.histplot(data=df, x=variable, kde=True,element=\"step\",ax=axes[0]) \n",
        "  stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "  sns.boxplot(x=df[variable],ax=axes[2])\n",
        "  \n",
        "  axes[0].set_title('Histogram')\n",
        "  axes[1].set_title('QQ Plot')\n",
        "  axes[2].set_title('Boxplot')\n",
        "  fig.suptitle(f\"{variable}\", fontsize=30,y=1.05)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "  try:  \n",
        "    encoder= OrdinalEncoder(encoding_method='arbitrary', variables = [f\"{column}_ordinal_encoder\"])\n",
        "    df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "  \n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_ordinal_encoder\"],axis=1,inplace=True)\n",
        "    \n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng,column):\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### Winsorizer iqr\n",
        "  try: \n",
        "    disc=Winsorizer(\n",
        "        capping_method='iqr', tail='both', fold=1.5, variables = [f\"{column}_iqr\"])\n",
        "    df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_iqr\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_iqr\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  return df_feat_eng,list_methods_worked\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng,column):\n",
        "\n",
        "  list_methods_worked = []\n",
        "\n",
        "  ### LogTransformer base e\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_e\"])\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_e\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_e\"],axis=1,inplace=True)\n",
        "\n",
        "    ### LogTransformer base 10\n",
        "  try: \n",
        "    lt = vt.LogTransformer(variables = [f\"{column}_log_10\"],base='10')\n",
        "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_log_10\")\n",
        "  except: \n",
        "    df_feat_eng.drop([f\"{column}_log_10\"],axis=1,inplace=True)\n",
        "\n",
        "  ### ReciprocalTransformer\n",
        "  try:\n",
        "    rt = vt.ReciprocalTransformer(variables = [f\"{column}_reciprocal\"])\n",
        "    df_feat_eng =  rt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_reciprocal\"],axis=1,inplace=True)\n",
        "\n",
        "  ### PowerTransformer\n",
        "  try:\n",
        "    pt = vt.PowerTransformer(variables = [f\"{column}_power\"])\n",
        "    df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_power\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_power\"],axis=1,inplace=True)\n",
        "\n",
        "  ### BoxCoxTransformer\n",
        "  try:\n",
        "    bct = vt.BoxCoxTransformer(variables = [f\"{column}_box_cox\"])\n",
        "    df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_box_cox\")\n",
        "  except:\n",
        "    df_feat_eng.drop([f\"{column}_box_cox\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  ### YeoJohnsonTransformer\n",
        "  try:\n",
        "    yjt = vt.YeoJohnsonTransformer(variables = [f\"{column}_yeo_johnson\"])\n",
        "    df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "    list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "  except:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  return df_feat_eng,list_methods_worked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering Spreadsheet Summary\n",
        "\n",
        "![FeatureEngineeringSpreadsheet](../media/featureengineering.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, you can see the Feature Engineering Transformers that we will use. To run these transformers, we have to follow four steps:\n",
        "* Step 1: Select variable(s)\n",
        "* Step 2: Create a separate dataframe with your variable(s)\n",
        "* Step 3: Create engineered variables(s), apply the transformation(s), assess engineered variables distribution and select the most suitable method for each variable\n",
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Categorical Enconding`\n",
        "\n",
        "We use categorical encoding to convert the variable names into numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering= ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create engineered variables(s) apply the transformation(s), assess engineered variables distribution and select most suitable method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='ordinal_encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nothing appears to be out of place; all variables are converted to numbers. Thus, we can now proceed with applying the transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = variables_engineering)\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Numerical Transformation`\n",
        "\n",
        "Next, we are going to work on numerical transformations. By applying the Numerical Transformation, we are trying to normalize the data by making it less skewed, adding an even distribution of the underlying data and making it more symmetrical.\n",
        "\n",
        "We have many variables that contain zeros, like the house which don't have a second floor or the wood deck. That will cause a substantial negative kurtosis but won't amend. Still, while normalizing the rest of the data, we can leave that as it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering = ['1stFlrSF', \n",
        "                    '2ndFlrSF', \n",
        "                    'BsmtFinSF1', \n",
        "                    'BsmtUnfSF', \n",
        "                    'EnclosedPorch', \n",
        "                    'GarageArea', \n",
        "                    'GrLivArea', \n",
        "                    'LotArea', \n",
        "                    'LotFrontage', \n",
        "                    'MasVnrArea', \n",
        "                    'OpenPorchSF', \n",
        "                    'TotalBsmtSF', \n",
        "                    'WoodDeckSF']\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create engineered variables(s) apply the transformation(s), assess engineered variables distribution and select most suitable method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTES:\n",
        "* `1stFlrSF` and `GrLivArea` seem to perform well to the `log_e`, `box_cox` and `yeo_johnson` methods. In our case, we will try using `log_e` for these variables and trim them off the outliers. \n",
        "In the Sale Price Study (Notebook two), we noticed that some outliers have other vital outlier variables. For instance, some of the largest `GrLivArea` had very low `SalePrice` compared to the rest of the data, which we could remove. Yet, removing these records from our data will imbalance our train and test sets since we first run it through the cleaning pipeline. Thus we will use the `Feature Engine Windsoriser`, which is the transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers. \n",
        "Still, that doesn't mean that our model performance will look good, so that we will return to this later. \n",
        "\n",
        "* For `2ndFlrSF`, `BsmtFinSF1`, `BsmtUnfSF`, `GarageArea`, `MasVnrArea`, `OpenPorchSF`, `TotalBsmtSF` and `WoodDeckSF` we will use `power` transformer as it keeps the strong kurtosis that these variables carry with all their zeros whilst normalizing the rest of the data.\n",
        "\n",
        "* `EnclosedPorch` doesn't have enough data that aren't zeros to justify using the `power` transformer.\n",
        "\n",
        "* `LotArea` and `LotFrontage` contain a small number of zeros that are well adapted to `log_e` and `yeo_johnson`, so in our case, we will use 'log_e`.\n",
        "\n",
        "  ![NumericalTransformation](../media/numerical.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = vt.LogTransformer(variables = [\n",
        "    '1stFlrSF', \n",
        "    'GrLivArea', \n",
        "    'LotArea', \n",
        "    'LotFrontage', ])\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = vt.PowerTransformer(variables = [\n",
        "    '2ndFlrSF', \n",
        "    'BsmtFinSF1', \n",
        "    'BsmtUnfSF', \n",
        "    'GarageArea', \n",
        "    'MasVnrArea',\n",
        "    'OpenPorchSF',\n",
        "    'TotalBsmtSF',\n",
        "    'WoodDeckSF', ])\n",
        "TrainSet = encoder.fit_transform(TrainSet)\n",
        "TestSet = encoder.transform(TestSet)\n",
        "\n",
        "print(\"* Categorical encoding - ordinal transformation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Outlier Trimmer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.outliers import OutlierTrimmer\n",
        "\n",
        "variables_engineering = ['SalePrice', 'GrLivArea']\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create engineered variables(s) apply the transformation(s), assess engineered variables distribution and select most suitable method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_transformed = OutlierTrimmer(capping_method='iqr', tail='both', fold=1.5, variables=variables_engineering)\n",
        "df_transformed = df_transformed.fit_transform(df_engineering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_histogram_and_boxplot(df):\n",
        "  for col in df.columns:\n",
        "    fig, axes = plt.subplots(nrows=2 ,ncols=1 ,figsize=(7,7), gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        "    sns.boxplot(data=df, x=col, ax=axes[0])\n",
        "    sns.histplot(data=df, x=col, kde=True, ax=axes[1])\n",
        "    fig.suptitle(f\"{col} Distribution - Boxplot and Histogram\")\n",
        "    plt.show()\n",
        "\n",
        "    IQR = df[col].quantile(q=0.75) - df[col].quantile(q=0.25)\n",
        "    print(\n",
        "        f\"This is the range where a datapoint is not an outlier: from \"\n",
        "        f\"{(df[col].quantile(q=0.25) - 1.5*IQR).round(2)} to \"\n",
        "        f\"{(df[col].quantile(q=0.75) + 1.5*IQR).round(2)}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"========= Before Transformation ========= \\n\")\n",
        "plot_histogram_and_boxplot(TrainSet[['SalePrice', 'GrLivArea']])\n",
        "print(\"\\n\\n ========= After Transformation =========\")\n",
        "plot_histogram_and_boxplot(df=df_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"* The dataset has {len(TrainSet)} rows, considering outliers.\")\n",
        "\n",
        "transformer = OutlierTrimmer(\n",
        "    variables=['SalePrice', 'GrLivArea'],\n",
        "    tail = 'both',\n",
        "    capping_method='iqr',\n",
        "    fold=1.5\n",
        ")\n",
        "\n",
        "transformer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = transformer.transform(TrainSet) , transformer.transform(TestSet)\n",
        "\n",
        "\n",
        "print(f\"* Once it is transformed with OutlierTrimmer, dataset has {len(TrainSet)} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Winsorizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Step 1: Select variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.outliers import Winsorizer\n",
        "\n",
        "variables_engineering = ['SalePrice', 'GrLivArea']\n",
        "variables_engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create a separate dataframe, with your variable(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create engineered variables(s) apply the transformation(s), assess engineered variables distribution and select most suitable method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='outlier_winsorizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 4 - Apply the selected transformation to the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformer = Winsorizer(\n",
        "    capping_method='iqr', \n",
        "    tail='both', \n",
        "    fold=1.5, \n",
        "    variables=variables_engineering)\n",
        "transformer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = transformer.transform(TrainSet) , transformer.transform(TestSet)\n",
        "\n",
        "print(\"* Winsorizer transformation done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Smart Correlation Selection`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variable(s)\n",
        "\n",
        "NOTE: We don't need to select any variables, since all variables for this transformer are needed. Thus we will move directly to\n",
        "* Step 2: Create a separate dataframe, with your variable(s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = TrainSet.copy()\n",
        "df_engineering.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Create engineered variables(s) applying the transformation(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.8,selection_method=\"variance\", missing_values='ignore')\n",
        "\n",
        "corr_sel.fit_transform(df_engineering)\n",
        "corr_sel.correlated_feature_sets_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_sel.features_to_drop_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  The list below shows the transformations needed for feature engineering:\n",
        "  \n",
        "  * Ordinal Encoder: ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']\n",
        "\n",
        "  * Numerical Transformation: ['1stFlrSF', '2ndFlrSF', 'BsmtFinSF1', 'BsmtUnfSF', 'EnclosedPorch', \n",
        "  'GarageArea', 'GrLivArea', 'LotArea', 'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF', \n",
        "  'WoodDeckSF', 'TotalArea']\n",
        "\n",
        "    * Log Transformer: ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']\n",
        "\n",
        "    * Power Transformer: ['2ndFlrSF', 'BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'MasVnrArea', 'OpenPorchSF','TotalBsmtSF', 'WoodDeckSF']\n",
        "\n",
        "  * Outlier Trimmer: ['SalePrice', 'GrLivArea', 'TotalArea']\n",
        "\n",
        "    * Winsorizer: ['SalePrice', 'GrLivArea']\n",
        "\n",
        "\n",
        "* Smart Correlated Selection - Features to drop: ['1stFlrSF', 'GarageYrBlt']\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
